#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
#pre-calculate some useful quantities
ltheta=log(theta)
lphi=log(phi)
#determine the number of locations in each group
tab=rep(0,nclustmax)
tmp=table(z)
tab[as.numeric(names(tmp))]=tmp
#calculate log-probability
tmp=matrix(NA,nobs,nclustmax)
for (i in 1:nclustmax){
ltheta1=matrix(ltheta[i,],nobs,nloc,byrow=T)
tmp[,i]=rowSums(dat*ltheta1)+lphi[i]
}
#sample z
for (i in 1:nobs){
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
ind1=which(ind==1)
z[i]=ind1
tab[ind1]=tab[ind1]+1
}
z
#pre-calculate some useful quantities
ltheta=log(theta)
lphi=log(phi)
#determine the number of locations in each group
tab=rep(0,nclustmax)
tmp=table(z)
tab[as.numeric(names(tmp))]=tmp
#calculate log-probability
tmp=matrix(NA,nobs,nclustmax)
for (i in 1:nclustmax){
ltheta1=matrix(ltheta[i,],nobs,nloc,byrow=T)
tmp[,i]=rowSums(dat*ltheta1)+lphi[i]
}
#sample z
for (i in 1:nobs){
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
ind1=which(ind==1)
z[i]=ind1
tab[ind1]=tab[ind1]+1
}
i
prob
tmp2
tmp1
cond=tab==0
sum(cond)
lphi[i]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
lphi[i]
#pre-calculate some useful quantities
ltheta=log(theta)
lphi=log(phi)
#determine the number of locations in each group
tab=rep(0,nclustmax)
tmp=table(z)
tab[as.numeric(names(tmp))]=tmp
#calculate log-probability
tmp=matrix(NA,nobs,nclustmax)
for (i in 1:nclustmax){
ltheta1=matrix(ltheta[i,],nobs,nloc,byrow=T)
tmp[,i]=rowSums(dat*ltheta1)+lphi[i]
}
#sample z
for (i in 1:nobs){
tab[z[i]]=tab[z[i]]-1
prob=rep(NA,nclustmax)
cond=tab==0
prob[ cond]=lphi[z[i]]+lgamma(nloc*psi)-nloc*lgamma(psi)+sum(lgamma(dat[i,]+psi))-lgamma(n[i]+nloc*psi) #log probability for a new group
prob[!cond]=tmp[i,!cond]
#get normalized probs
tmp1=prob-max(prob) #for numerical stability
tmp2=exp(tmp1) #exponentiate log probability
prob=tmp2/sum(tmp2) #normalize to sum to 1
#draw from multinomial distrib
ind=rmultinom(1,size=1,prob=prob)
ind1=which(ind==1)
z[i]=ind1
tab[ind1]=tab[ind1]+1
}
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\cluster_tsegments_loc')
library('Rcpp')
sourceCpp('aux1.cpp')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
dat=data.matrix(dat)
n=rowSums(dat)
nobs=nrow(dat)
nloc=ncol(dat)
lo=0.000000000000001
#priors
psi=0.01
gamma1=0.1
#starting values
nclustmax=10
z=sample(1:nclustmax,size=nobs,replace=T)
theta=matrix(1/nloc,nclustmax,nloc)
phi=rep(1/nclustmax,nclustmax)
#store results
ngibbs=1000
store.phi=matrix(NA,ngibbs,nclustmax)
store.z=matrix(NA,ngibbs,nobs)
store.theta=matrix(NA,ngibbs,nclustmax*nloc)
store.loglikel=matrix(NA,ngibbs,1)
#gibbs sampler
nburn=ngibbs/2
for (i in 1:ngibbs){
print(i)
#occasionally re-order this
# if (i<nburn & i%%50==0){
#   ind=order(phi,decreasing=T)
#   theta=theta[ind,]
#   phi=phi[ind]
#   znew=z
#   for (j in 1:nclustmax){
#     znew[z==j]=ind
#   }
# }
#draw samples from FCD's
z=sample.z(dat=dat,theta=theta,phi=phi,
nobs=nobs,nclustmax=nclustmax,nloc=nloc,z=z,n=n)
# z=z.true
v=sample.v(z=z,nclustmax=nclustmax,gamma1=gamma1)
phi=GetPhi(vec=c(v,1),nclustmax=nclustmax)
theta=sample.theta(dat=dat,nclustmax=nclustmax,nloc=nloc,z=z,psi=psi)
#to avoid numerical issues
theta[theta<lo]=lo
# theta=theta.true
#get logl
tmp=sum(dat*log(theta)[z,])+sum(dbeta(v,1,gamma1,log=T))+sum((psi-1)*log(theta))
#store results
store.loglikel[i]=tmp
store.theta[i,]=theta
store.phi[i,]=phi
store.z[i,]=z
}
ind=order(phi,decreasing=T)
ind
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\cluster_tsegments_loc')
library('Rcpp')
sourceCpp('aux1.cpp')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
dat=data.matrix(dat)
n=rowSums(dat)
nobs=nrow(dat)
nloc=ncol(dat)
lo=0.000000000000001
#priors
psi=0.01
gamma1=0.1
#starting values
nclustmax=10
z=sample(1:nclustmax,size=nobs,replace=T)
theta=matrix(1/nloc,nclustmax,nloc)
phi=rep(1/nclustmax,nclustmax)
#store results
ngibbs=1000
store.phi=matrix(NA,ngibbs,nclustmax)
store.z=matrix(NA,ngibbs,nobs)
store.theta=matrix(NA,ngibbs,nclustmax*nloc)
store.loglikel=matrix(NA,ngibbs,1)
#gibbs sampler
nburn=ngibbs/2
for (i in 1:ngibbs){
print(i)
#occasionally re-order this
if (i<nburn & i%%50==0){
ind=order(phi,decreasing=T)
theta=theta[ind,]
phi=phi[ind]
znew=z
for (j in 1:nclustmax){
znew[z==ind[j]]=j
}
z=znew
}
#draw samples from FCD's
z=sample.z(dat=dat,theta=theta,phi=phi,
nobs=nobs,nclustmax=nclustmax,nloc=nloc,z=z,n=n)
# z=z.true
v=sample.v(z=z,nclustmax=nclustmax,gamma1=gamma1)
phi=GetPhi(vec=c(v,1),nclustmax=nclustmax)
theta=sample.theta(dat=dat,nclustmax=nclustmax,nloc=nloc,z=z,psi=psi)
#to avoid numerical issues
theta[theta<lo]=lo
# theta=theta.true
#get logl
tmp=sum(dat*log(theta)[z,])+sum(dbeta(v,1,gamma1,log=T))+sum((psi-1)*log(theta))
#store results
store.loglikel[i]=tmp
store.theta[i,]=theta
store.phi[i,]=phi
store.z[i,]=z
}
plot(store.loglikel,type='l')
plot(store.phi[ngibbs,],type='h')
rango=range(c(theta,theta.true))
plot(theta[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
library('MCMCpack')
set.seed(3)
nobs=1000
nloc=150
nclust=5
z.true=z=sample(1:nclust,size=nobs,replace=T)
theta.true=theta=rdirichlet(nclust,rep(0.01,nloc))
image(theta.true)
n=round(runif(nobs,min=200,max=250))
obs=matrix(NA,nobs,nloc)
for (i in 1:nobs){
tmp=theta[z[i],]
obs[i,]=rmultinom(1,size=n[i],prob=tmp)
}
image(obs)
rowSums(obs)[1:5]
n[1:5]
setwd('U:\\GIT_models\\cluster_tsegments_loc')
rango=range(c(theta,theta.true))
plot(theta[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
fim=data.frame(zestim=store.z[ngibbs,],ztrue=z.true)
table(fim)
rango=range(c(theta,theta.true))
plot(theta[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
theta.estim=store.theta[ngibbs,]
rango=range(c(theta.estim,theta.true))
plot(theta.estim[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
theta.estim=matrix(store.theta[ngibbs,],nclustmax,nloc)
rango=range(c(theta.estim,theta.true))
plot(theta.estim[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
fim=data.frame(zestim=store.z[ngibbs,],ztrue=z.true)
table(fim)
seq1=c(2,3,5,4,1)
tmp=matrix(store.theta[ngibbs,],nclustmax,nloc)
theta.estim=tmp[seq1,]
rango=range(c(theta.estim,theta.true))
plot(theta.estim[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(3)
nobs=1000
nloc=150
nclust=10
z.true=z=sample(1:nclust,size=nobs,replace=T)
theta.true=theta=rdirichlet(nclust,rep(0.01,nloc))
image(theta.true)
n=round(runif(nobs,min=200,max=250))
obs=matrix(NA,nobs,nloc)
for (i in 1:nobs){
tmp=theta[z[i],]
obs[i,]=rmultinom(1,size=n[i],prob=tmp)
}
image(obs)
rowSums(obs)[1:5]
n[1:5]
setwd('U:\\GIT_models\\cluster_tsegments_loc')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(3)
nobs=1000
nloc=150
nclust=10
z.true=z=sample(1:nclust,size=nobs,replace=T)
theta.true=theta=rdirichlet(nclust,rep(0.01,nloc))
image(theta.true)
n=round(runif(nobs,min=50,max=250))
obs=matrix(NA,nobs,nloc)
for (i in 1:nobs){
tmp=theta[z[i],]
obs[i,]=rmultinom(1,size=n[i],prob=tmp)
}
image(obs)
rowSums(obs)[1:5]
n[1:5]
setwd('U:\\GIT_models\\cluster_tsegments_loc')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\cluster_tsegments_loc')
library('Rcpp')
sourceCpp('aux1.cpp')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
dat=data.matrix(dat)
n=rowSums(dat)
nobs=nrow(dat)
nloc=ncol(dat)
lo=0.000000000000001
#priors
psi=0.01
gamma1=0.1
#starting values
nclustmax=10
z=sample(1:nclustmax,size=nobs,replace=T)
theta=matrix(1/nloc,nclustmax,nloc)
phi=rep(1/nclustmax,nclustmax)
#store results
ngibbs=1000
store.phi=matrix(NA,ngibbs,nclustmax)
store.z=matrix(NA,ngibbs,nobs)
store.theta=matrix(NA,ngibbs,nclustmax*nloc)
store.loglikel=matrix(NA,ngibbs,1)
#gibbs sampler
nburn=ngibbs/2
for (i in 1:ngibbs){
print(i)
#occasionally re-order this
if (i<nburn & i%%50==0){
ind=order(phi,decreasing=T)
theta=theta[ind,]
phi=phi[ind]
znew=z
for (j in 1:nclustmax){
znew[z==ind[j]]=j
}
z=znew
}
#draw samples from FCD's
z=sample.z(dat=dat,theta=theta,phi=phi,
nobs=nobs,nclustmax=nclustmax,nloc=nloc,z=z,n=n)
# z=z.true
v=sample.v(z=z,nclustmax=nclustmax,gamma1=gamma1)
phi=GetPhi(vec=c(v,1),nclustmax=nclustmax)
theta=sample.theta(dat=dat,nclustmax=nclustmax,nloc=nloc,z=z,psi=psi)
#to avoid numerical issues
theta[theta<lo]=lo
# theta=theta.true
#get logl
tmp=sum(dat*log(theta)[z,])+sum(dbeta(v,1,gamma1,log=T))+sum((psi-1)*log(theta))
#store results
store.loglikel[i]=tmp
store.theta[i,]=theta
store.phi[i,]=phi
store.z[i,]=z
}
plot(store.loglikel,type='l')
plot(store.phi[ngibbs,],type='h')
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\cluster_tsegments_loc')
library('Rcpp')
sourceCpp('aux1.cpp')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
dat=data.matrix(dat)
n=rowSums(dat)
nobs=nrow(dat)
nloc=ncol(dat)
lo=0.000000000000001
#priors
psi=0.01
gamma1=0.1
#starting values
nclustmax=20
z=sample(1:nclustmax,size=nobs,replace=T)
theta=matrix(1/nloc,nclustmax,nloc)
phi=rep(1/nclustmax,nclustmax)
#store results
ngibbs=1000
store.phi=matrix(NA,ngibbs,nclustmax)
store.z=matrix(NA,ngibbs,nobs)
store.theta=matrix(NA,ngibbs,nclustmax*nloc)
store.loglikel=matrix(NA,ngibbs,1)
#gibbs sampler
nburn=ngibbs/2
for (i in 1:ngibbs){
print(i)
#occasionally re-order this
if (i<nburn & i%%50==0){
ind=order(phi,decreasing=T)
theta=theta[ind,]
phi=phi[ind]
znew=z
for (j in 1:nclustmax){
znew[z==ind[j]]=j
}
z=znew
}
#draw samples from FCD's
z=sample.z(dat=dat,theta=theta,phi=phi,
nobs=nobs,nclustmax=nclustmax,nloc=nloc,z=z,n=n)
# z=z.true
v=sample.v(z=z,nclustmax=nclustmax,gamma1=gamma1)
phi=GetPhi(vec=c(v,1),nclustmax=nclustmax)
theta=sample.theta(dat=dat,nclustmax=nclustmax,nloc=nloc,z=z,psi=psi)
#to avoid numerical issues
theta[theta<lo]=lo
# theta=theta.true
#get logl
tmp=sum(dat*log(theta)[z,])+sum(dbeta(v,1,gamma1,log=T))+sum((psi-1)*log(theta))
#store results
store.loglikel[i]=tmp
store.theta[i,]=theta
store.phi[i,]=phi
store.z[i,]=z
}
plot(store.loglikel,type='l')
plot(store.phi[ngibbs,],type='h')
fim=data.frame(zestim=store.z[ngibbs,],ztrue=z.true)
table(fim)
library('MCMCpack')
set.seed(3)
nobs=1000
nloc=150
nclust=10
z.true=z=sample(1:nclust,size=nobs,replace=T)
theta.true=theta=rdirichlet(nclust,rep(0.01,nloc))
image(theta.true)
n=round(runif(nobs,min=50,max=250))
obs=matrix(NA,nobs,nloc)
for (i in 1:nobs){
tmp=theta[z[i],]
obs[i,]=rmultinom(1,size=n[i],prob=tmp)
}
image(obs)
rowSums(obs)[1:5]
n[1:5]
fim=data.frame(zestim=store.z[ngibbs,],ztrue=z.true)
table(fim)
seq1=c(4,5,6,2,10,3,8,9,1,7)
tmp=matrix(store.theta[ngibbs,],nclustmax,nloc)
theta.estim=tmp[seq1,]
rango=range(c(theta.estim,theta.true))
plot(theta.estim[1:5,],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
seq1=c(4,5,6,2,10,3,8,9,1,7)
tmp=matrix(store.theta[ngibbs,],nclustmax,nloc)
theta.estim=tmp[seq1,]
rango=range(c(theta.estim,theta.true))
plot(theta.estim[1:length(seq1),],theta.true,xlim=rango,ylim=rango)
lines(rango,rango)
fim=data.frame(zestim=store.z[ngibbs,],ztrue=z.true)
table(fim)
